akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  actor {
    deployment {
      /semantic-router {
        router = smallest-mailbox-pool
        nr-of-instances = 5
        pool-dispatcher {
          # Dispatcher is the name of the event-based dispatcher
          type = PinnedDispatcher
          # What kind of ExecutionService to use
          executor = "thread-pool-executor"
          # Configuration for the thread pool
          thread-pool-executor {
            core-pool-size-min = 5
            core-pool-size-max = 5
          }
        }

      }
    }

  }
  # Properties for akka.kafka.ConsumerSettings can be
  # defined in this section or a configuration section with
  # the same layout.
  kafka {
    delete.topic.enable = true
    auto.create.topics.enable = true
    consumer {
      # Tuning property of scheduled polls.
      poll-interval = 50ms

      # Tuning property of the `KafkaConsumer.poll` parameter.
      # Note that non-zero value means that blocking of the thread that
      # is executing the stage will be blocked.
      poll-timeout = 50ms

      # The stage will be await outstanding offset commit requests before
      # shutting down, but if that takes longer than this timeout it will
      # stop forcefully.
      stop-timeout = 30s

      # How long to wait for `KafkaConsumer.close`
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `TimeoutException`.
      commit-timeout = 15s

      # If the KafkaConsumer can't connect to the broker the poll will be
      # aborted after this timeout. The KafkaConsumerActor will throw
      # org.apache.kafka.common.errors.WakeupException, which can be handled
      # with Actor supervision strategy.
      wakeup-timeout = 10s

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
      # can be defined in this configuration section.
      kafka-clients {
        # Disable auto-commit by default
        enable.auto.commit = false
      }
    }
    producer {
      # Tuning parameter of how many sends that can run in parallel.
      parallelism = 100

      # How long to wait for `KafkaProducer.close`
      close-timeout = 60s

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the producer stages. Some blocking may occur.
      # When this value is empty, the dispatcher configured for the stream
      # will be used.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
      # can be defined in this configuration section.
      kafka-clients {
      }
      offset.storage = "kafka"
      dual.commit.enabled = false
      auto.commit.enable = true
    }
  }
}

ipsm = {
  supported-channel-types = ["MM"] // MQTT-MQTT only
  //  supported-channel-types = ["KK"] // Kafka-Kafka only
  //  supported-channel-types = ["MM", "KK"] // Both MQTT-MQTT and Kafka-Kafka
  supported-channel-types = ${?IPSM_BROKER_TYPES}
  db-sqlite {
    driverClassName = org.sqlite.JDBC
    jdbcUrl = "jdbc:sqlite:./data/ipsm.sqlite"
  }
  http {
    port = "8080"
    port = ${?IPSM_REST_PORT}
    host = "0.0.0.0"
    host = ${?IPSM_REST_HOST}
  }
  mqtt {
    messageSizeLimitInKB = 256
    messageSizeLimitInKB = ${?IPSM_MQTT_MSG_SIZE}
    source {
      host = "127.0.0.1"
      host = ${?IPSM_MQTT_SRC_HOST}
      port = 1883
      port = ${?IPSM_MQTT_SRC_PORT}
    }
    target {
      host = "127.0.0.1"
      host = ${?IPSM_MQTT_TRG_HOST}
      port = 1883
      port = ${?IPSM_MQTT_TRG_PORT}
    }
  }
  kafka = {
    host = "127.0.0.1"
    host = ${?IPSM_KAFKA_HOST}
    port = 29092
    port = ${?IPSM_KAFKA_PORT}
  }
}
